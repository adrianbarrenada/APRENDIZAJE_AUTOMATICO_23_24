{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianbarrenada/APRENDIZAJE_AUTOMATICO_23_24/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRUPO A04\n",
        "\n",
        "Pablo Ardila, Hugo López y Adrián Barreñada.\n",
        "##Practica 1##\n",
        "\n",
        "###Enunciado###\n",
        "Crea un modelo de Red de Neuronas Artificiales que sea capaz de reconocer y clasificar\n",
        "imágenes de ropa en sus diferentes tipologías. Este modelo será definido, configurado,\n",
        "entrenado, evaluado y mejorado para posteriormente usarlo para hacer predicciones.\n",
        "Para ello tendréis que crear un modelo en Keras aplicando de una tirada todos los pasos\n",
        "al conjunto de datos Fashion-MNIST, precargado en Keras y muy parecido al que vimos\n",
        "en clase de reconocimiento de cifras.\n",
        "Fashion-MNIST es un conjunto de datos de las imágenes de los artículos de Zalando\n",
        "(www.zalando.com), una tienda de moda online alemana especializada en ventas de\n",
        "ropa y zapatos. El conjunto de datos contiene 70K imágenes en escala de grises en 10\n",
        "categorías. Estas imágenes muestran prendas individuales de ropa en baja resolución\n",
        "(28 x 28 píxeles):\n",
        "Se usan 60K imágenes para entrenar la red y 10K imágenes para evaluar la precisión con\n",
        "la que la red aprende a clasificar las imágenes\n",
        "####Introducción####\n",
        "Visto el enunciado que tenemos por delante, debemos de plantearnos una cosa importante antes de comenzar a resolver nuestro problema:\n",
        "\n",
        "¿Cuál es la forma en la que necesitamos enseñar a la red? Sabemos que los datos que nos dan y que debemos cargar están etiquetados. Es decir, cada dato esta catalogado y cada prenda tiene un número que se identifica con zapato, camisa...\n",
        "\n",
        "Por lo que estamos ante un claro ejemplo de aprendizaje supervisado de clasificación ya que todos los datos están etiquetados en **categorías** y nuestro algoritmo va a recibir un **feedback** en cada iteración. Además, sabemos que nos encontramos ante un caso de aprendizaje con refuerzo ya que al estar todos los datos etiquetados la red recibe la información de si lo que ha hecho está bien o está mal\n",
        "\n",
        "Además, debemos de organizarnos para poder realizar la tarea con éxito. Para ello tendremos un periodo, el más largo, de trabajo individual donde iremos completando el código cada uno de forma individual y escribiendo los avances correspondientes en este archivo. Como norma, se deberá de informar y justificar cada cambio realizado\n",
        "\n",
        "####Codigo de Resolución####\n",
        "Comenzamos declarando todas las librerías necesarias para poder trabajar con redes neuronales y para poder realizar nuestro código."
      ],
      "metadata": {
        "id": "4IZkY4oEXqlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "0lKsVXfNYFnV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez cargadas las librerías necesarias nos disponemos a cargar los datos con los que vamos a trabajar, es decir las imágenes de las prendas de Zalando."
      ],
      "metadata": {
        "id": "Gfi6bgTdCv9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cargar los datos de fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "QgZlP66UCq4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c93487-89d2-4669-843b-5152846106d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación,  nos disponemos a analizar los datos. Ya que no los conocemos con exactitud, o si los conocemos con exactitud (como pone en el enunciado) debemos de confirmar que los datos cargados son los correctos y además debemos de comprobar de alguna forma antes de empezar el código que los datos esten bien etiquetados."
      ],
      "metadata": {
        "id": "B-iD7rSNCdno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las dimensiones de las imágenes de entrenamiento y prueba\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "print(train_labels[30001])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM1rt6a_ZURN",
        "outputId": "0a35341c-555e-4469-973f-a32b0c8cae91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar la librería numpy si no está instalada\n",
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dkk-qPAJbVhc",
        "outputId": "83583944-5b9e-4abe-8b78-ac669538a0ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este primer vistazo, observamos que disponemos de 60000 imágenes de entrenamiento de un tamaño de 28x28 y de 10000 imágenes de test del mismo tamaño. Ahora, se mostrará una imagen cualquiera para ver como son las matrices con las que trabajamos"
      ],
      "metadata": {
        "id": "qF9-_WH7ESQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(linewidth=145)\n",
        "\n",
        "# Mostrar la etiqueta y la imagen de ejemplo\n",
        "print(train_labels[30001])  # etiqueta = 3 -> vestido\n",
        "print(np.matrix(train_images[30001]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x08ZPp54eROh",
        "outputId": "a6afbda2-2c22-4815-c94f-7853401ee822"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "[[  0   0   0   0   0   0   0   3   0  23  87   0   3   1   4   0  19  95   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  75 153   8   0   0   0   0  90 149   8   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   4   0  62 129 118  46   3   3  74 121 116  11   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   4   0  69 118 108 126 125 129 125 108 115  13   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   4   0  64 113  90  93  97  95  95 102 123  16   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  59 115  92  92  90  98  97  93 116  18   0   3   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   4   0  49 121  88  90  90  90  92  85 123  19   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   4   0  42 143  93  92  88  87  88  85 116  11   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  46 133  87  85  82  83  85  78 113   8   0   3   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  46 138  85  87  82  85  83  75 111   9   0   3   1   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  49 141  82  83  77  75  74  72 100  21   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   4   0  31 141  93 111 120 129 128 111 115  37   0   4   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   1   0 105 151 143 166 148 149 148 149 148 125   0   0   1   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   3   0  34 171 156 177 185 166 164 171 185 162 166  52   0   4   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0 126 180 154 174 179 185 162 169 180 166 161 136   0   3   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   3 199 162 161 171 172 172 159 179 167 169 169 174   1   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0  59 185 153 177 172 169 157 154 195 182 171 172 167  54   0   4   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0 133 177 148 180 174 174 161 159 200 182 156 182 171 134   0   3   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 184 172 161 187 179 171 172 174 185 185 143 189 167 185   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  36 177 164 164 195 192 169 195 177 184 190 143 189 171 171  57   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  93 184 156 167 190 212 161 200 182 187 200 149 180 177 169 120   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 131 185 151 180 189 227 153 202 190 179 199 161 172 195 162 166   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 166 187 157 184 182 238 156 207 192 189 207 176 177 208 153 192   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0  13 194 184 159 192 179 245 151 212 192 195 212 185 176 210 159 204  46   0   0   0   0   0]\n",
            " [  0   0   0   0   0  36 177 176 161 190 177 243 138 212 187 199 212 192 169 215 171 195  85   0   0   0   0   0]\n",
            " [  0   0   0   0   0  69 190 171 182 190 185 250 138 220 190 197 210 202 187 204 169 174 115   0   0   0   0   0]\n",
            " [  0   0   0   0   0  60 192 126 182 157 189 255 126 231 189 192 233 207 197 192 166 172 134   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  47  37  46  74 121 141  87 138  93  75 133  98 111  82  39  24   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez visto con números, deberemos de imprimirlo de una forma más visible y clara. Para ello se prueba a imprimir con matplotlib:"
      ],
      "metadata": {
        "id": "tOXNhal5ei2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prendaejemplo1 = train_images[30001]\n",
        "plt.imshow(prendaejemplo1, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "-NqzQahUKHm7",
        "outputId": "cd3cd904-1220-4a77-ca80-6c92a229a00f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez vista la imagen sabemos que es un vestido y que está etiquetada como tal así que hemos comprobado nuestros datos, sabemos el tamaño que tienen y sabemos que hemos cargado los datos correctos.\n",
        "\n",
        "Ahora pasamos a expresar la escala de grises de las imágenes de entrenamiento del 0 al 1 dividiéndolas entre 255, de esta forma el código es más sencillo para la computadora. Además expresaremos la etiqueta de cada una de las imágenes como un vector para que converja más rápido (one-hot encoding). Usaremos un float de 32 para no perder decimales ya que así será preciso el número obtenido y no se perderá color ni carcaterísticas"
      ],
      "metadata": {
        "id": "jcZ1y2c58RYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.astype('float32')\n",
        "train_images = train_images / 255\n",
        "labels_no_cat = train_labels\n",
        "train_labels = to_categorical(train_labels)\n",
        "print(train_images.shape)\n",
        "print(train_labels[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF6JTaPR3AYe",
        "outputId": "35437f8b-af36-4222-de78-ae22137807f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Apartados 1 y 2"
      ],
      "metadata": {
        "id": "cjZ1n85uMfx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se sabe por el enunciado, que debemos de crear 8 redes de neuronas. Lo que hemos hecho para ahorrar código es crear una matriz de strings con cada uno de los 8 casos propuestos en el enunciado. Cada fila es uno de los casos.\n",
        "\n",
        "La primera columna, se atribuye al número de neuronas que hay en la primera capa. Solo tenemos 2 casos el caso de **10 neuronas** y el caso de **512 neuronas**.\n",
        "\n",
        "La segunda columna, es para saber la función de activación que tendrá nuestro algoritmo. Esta vez también hay solo 2 casos expuestos en nuestra matriz.\n",
        "\n",
        "El primero es la función de activación **relu**, esta función devuelve un 0 si el valor proporcionado es negativo y devuelve el mismo valor si es positivo *f(x) = max(0, x)*. Además, *relu* es utilizado debido a su simpleza computacional ya que evita cálculos complejos que otras funciones tienen como la tangente hiperbólica o la sigmoidea y supera el problema de la desaparición del gradiente, es decir los pesos nunca se vuelven muy pequeños de manera exponencial.\n",
        "\n",
        "El segundo es la función **sigmoid** o en español sigmoidea, que tiene esta forma *f(x) = 1 / (1 + exp(-x))*. Lo que se refleja en una curva en forma de S entre el cero y el uno. Esta función es suave y se utiliza sobre todo para los problemas de clasificación binaria donde se busca etiquetar una instancia.\n",
        "\n",
        "La tercera columna, se atribuye al optimizador, donde nos encontramos otra vez con dos casos.\n",
        "\n",
        "El primer optimizador es el **descenso de gradiente estocástico** *(SGD (Stochastic Gradient Descent))*. El objetivo principal es minimizar la función de pérdida. Para ello se actualizan iterativamente los pesos en la dirección opuesta al gradiente de la función de pérdida con respecto a los pesos. La palabra estocástico proviene de que se cojen aleatoriamente pequeñas muestras *(batch)*. Esto hace que el algoritmo sea eficiente para grandes conjuntos de datos ya que si se hace todo de una vez es más largo y complejo, además de ayudar a que  no aparezca el problema del sobrentrenamiento. Una desventaja de este optimizador es que a menudo se puede quedar atascado en mínimos locales, por lo que surgen mejoras como el SGDM o Adam que introducen conceptos de inercia o adaptación para mejorar el rendimiento o la estabilidad del sistema.\n",
        "\n",
        "El segundo optimizador es el **rmsprop**, este es una mejora del descenso de gradiente estocástico. Para ello la actualización de los pesos en RMSProp se realiza de manera individual para cada peso en cada iteración, adaptando el learning rate a las características de cada peso específico. Esto permite un ajuste más eficiente y efectivo de los pesos durante el entrenamiento.\n",
        "\n",
        "Para comprender el segundo optimizador debemos de saber que el learning rate o tasa de aprendizaje es un hiperparámetro muy importante que determina la magnitud de las actualizaciones de los pesos del modelo en cada iteración durante el periodo de entrenamiento. Cuanto mayor sea el learning rate más rápido convergerá nuestro algoritmo. Sin embargo, deberemos de tener cuidado ya que una tasa de aprendizaje demasiado alta provoca que las actualizaciones puedan ser demasiado drásticas haciendo que el optimizador se salte el mínimo global óptimo.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rb-frdkZG0PZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "red = [0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "matriz = [\n",
        "    [10, \"relu\", \"sgd\"],\n",
        "    [10, \"relu\", \"rmsprop\"],\n",
        "    [10, \"sigmoid\", \"sgd\"],\n",
        "    [10, \"sigmoid\", \"rmsprop\"],\n",
        "    [512, \"relu\", \"sgd\"],\n",
        "    [512, \"relu\", \"rmsprop\"],\n",
        "    [512, \"sigmoid\", \"sgd\"],\n",
        "    [512, \"sigmoid\", \"rmsprop\"]\n",
        "]"
      ],
      "metadata": {
        "id": "R5gn859RZv0H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después, hemos creado la función `GenerateTrain()`, que recibe como parámetros el número de neuronas de la primera capa, la función de activación, el optimizador, el número de épocas, la funcion de perdida y las etiquetas. Hemos incorporado la función `flatten()` dentro de la nuestra. `GenerateTrain()` utiliza como función de pérdida `categorical_crossentropy`, y devuelve el `summary()` de cada tipo de red además de que entrena ya la red con las condiciones especificadas.\n",
        "Cada una de estas redes se almacena en el vector red.\n",
        "\n",
        "La función `flatten()` se utiliza para transformar un array multidimensional (una matriz), a un array unidimensional (un vector). De esta forma, la convergencia será más rápida ya que para el programa es más fácil trabajar con arrays unidimensionales.\n",
        "\n",
        "Para programar esta función primero creamos un modelo secuencial el cual se almacena en la clase red.\n",
        "\n",
        "A continuación, se añade la capa de aplanamiento Flatten, este se encarga de transformar las imágenes de 28x28 en un vector plano unidimensional. Esta capa se utiliza para convertir los datos de entrada en un formato adecuado para para ser procesados por las neuronas densamente conectadas.\n",
        "\n",
        "Posteriormente, se añade una capa densa *Dense* con numero que viene dado por la variable de entrada neuronas. Además utiliza la función de activación aportada por la variable act.\n",
        "\n",
        "Cabe destacar que una capa densa de neuronas *(capa fully conected)* es aquella en la que todas las neuronas de la capa están conectadas con la capa anterior. Estas capas densas son muy utilizadas en modelos de clasificación y regresión. En este caso específico nos encontramos en uno de clasificación ya que a cad prenda se le asigna una categoría.\n",
        "\n",
        "Después de este paréntesis seguimos con el siguiente paso que consiste en añadir otra capa densa con 10 neuronas, esto se debe a que hay 10 categorías y por tanto asignamos una categoría por neurona de salida.\n",
        "\n",
        "Además usamos la función de activación softmax, la cual está comunmente utilizada en problemas de clasificación multiclase. Esto se debe a que realiza dos operaciones importantes de cara a la clasificación. La primera es la exponencial la cual provoca que haya diferencias entre ellos, y la segunda es la normalización que provoca que todos los valores estén entre 0 y 1 para dar como resultado una distribución de probabilidad. Esta distribución es nuestra probabilidad de que sea cada una de las prendas, es decir probabilidad de bota, de camisa...\n",
        "\n",
        "Lo siguiente que hacemos es mostrar por pantalla la arquitectura de la red neuronal, mostrando el número de parámetros entrenables de cada capa.\n",
        "\n",
        "A posteriori compilamos el optimizador usando el optimizador especificado en la variable opt y la funcion de pérdida vista en funperdida y la métrica de evaluación accuracy para ver el desempeño del modelo durante el entrenamiento.\n",
        "\n",
        "Finalmente entrenamos el modelo usando el método fit y especificamos el número de épocas en la variable epocas y usamos un batch_size de 128.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v1IziS_yDoEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def GenerateTrain (neuronas, act, opt, epocas, funperdida, etiquetas):\n",
        "  red = models.Sequential()\n",
        "  red.add(Flatten(input_shape = (28,28)))\n",
        "  red.add(layers.Dense(neuronas, activation=act))\n",
        "  red.add(layers.Dense(10, activation = 'softmax'))\n",
        "  red.summary()\n",
        "\n",
        "  red.compile(optimizer= opt,loss=funperdida,metrics=['accuracy'])#Define la funcion de perdida y la metrica que va a tener\n",
        "  entrenamiento = red.fit(train_images, etiquetas, epochs=epocas, batch_size=128)\n",
        "  return red\n",
        "\n",
        "for i in range(len(red)):\n",
        "  print(\"CASO\", i+1, \":  \", matriz[i][0], \" \", matriz[i][1], \" \", matriz[i][2])\n",
        "  red[i] = GenerateTrain (matriz[i][0], matriz[i][1], matriz[i][2], 5, 'categorical_crossentropy', train_labels )#pasar labels categoricas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCK6uDP8fTTM",
        "outputId": "74259cd9-24a0-466f-ab62-8bfd4a47cd47"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CASO 1 :   10   relu   sgd\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                7850      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7960 (31.09 KB)\n",
            "Trainable params: 7960 (31.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.2648 - accuracy: 0.5865\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.8177 - accuracy: 0.7040\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.7148 - accuracy: 0.7473\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.6547 - accuracy: 0.7794\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.6114 - accuracy: 0.7977\n",
            "CASO 2 :   10   relu   rmsprop\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7960 (31.09 KB)\n",
            "Trainable params: 7960 (31.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 4s 6ms/step - loss: 0.8998 - accuracy: 0.6934\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.5302 - accuracy: 0.8186\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.4803 - accuracy: 0.8346\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4558 - accuracy: 0.8427\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4401 - accuracy: 0.8471\n",
            "CASO 3 :   10   sigmoid   sgd\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7960 (31.09 KB)\n",
            "Trainable params: 7960 (31.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 2.1341 - accuracy: 0.3308\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 1.8493 - accuracy: 0.5439\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.6348 - accuracy: 0.6281\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 1.4669 - accuracy: 0.6461\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.3335 - accuracy: 0.6631\n",
            "CASO 4 :   10   sigmoid   rmsprop\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7960 (31.09 KB)\n",
            "Trainable params: 7960 (31.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 1.3901 - accuracy: 0.6662\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.8289 - accuracy: 0.7758\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.6311 - accuracy: 0.8038\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5446 - accuracy: 0.8208\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4993 - accuracy: 0.8307\n",
            "CASO 5 :   512   relu   sgd\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407050 (1.55 MB)\n",
            "Trainable params: 407050 (1.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.0213 - accuracy: 0.6857\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.6628 - accuracy: 0.7853\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.5843 - accuracy: 0.8104\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5419 - accuracy: 0.8219\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.5149 - accuracy: 0.8293\n",
            "CASO 6 :   512   relu   rmsprop\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_5 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407050 (1.55 MB)\n",
            "Trainable params: 407050 (1.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 8s 16ms/step - loss: 0.5587 - accuracy: 0.8020\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.3844 - accuracy: 0.8580\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3419 - accuracy: 0.8730\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3151 - accuracy: 0.8822\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2947 - accuracy: 0.8906\n",
            "CASO 7 :   512   sigmoid   sgd\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_6 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407050 (1.55 MB)\n",
            "Trainable params: 407050 (1.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 1.6840 - accuracy: 0.5719\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 1.1271 - accuracy: 0.7070\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.9278 - accuracy: 0.7285\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.8279 - accuracy: 0.7398\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.7670 - accuracy: 0.7498\n",
            "CASO 8 :   512   sigmoid   rmsprop\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407050 (1.55 MB)\n",
            "Trainable params: 407050 (1.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6143 - accuracy: 0.7846\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.4473 - accuracy: 0.8399\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4123 - accuracy: 0.8514\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.3867 - accuracy: 0.8605\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3674 - accuracy: 0.8664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez tenemos preparadas nuestras 8 redes, pasamos a evaluarlas con imágenes de test con las que no se ha entrenado para ver cuál es el verdadero porcentaje de acierto. Estas imágenes no han sido vistas nunca por nuestra red. En este caso, no vamos a vectorizar las imágenes de test, ya que al hacerlo nos hemos dado cuenta que la pérdida se hacía muy grande comparado con las imágenes de entrenamiento."
      ],
      "metadata": {
        "id": "Izijy-3grVKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32')\n",
        "test_images = test_images / 255\n",
        "print(test_images.shape)"
      ],
      "metadata": {
        "id": "fnX9mZhnrjqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140dfe57-ec46-4c2c-f428-215122eef221"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Volvemos a vectorizar (one-hot-encoding) las etiquetas de las imágenes de prueba. En este caso, las guardamos en una variable aparte porque más tarde necesitaremos poder acceder a las etiquetas de las imágenes de test de forma no vectorizada."
      ],
      "metadata": {
        "id": "nEO4WBVesWWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_labelsOH = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "Cg24lAtjuhEW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labelsOH[68])"
      ],
      "metadata": {
        "id": "Z0MeHfnHFIee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6e06b2-5ebe-490c-bd9f-bc0fc4bb0dfc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Apartado 4"
      ],
      "metadata": {
        "id": "Zy9OjsLZuBD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a evaluar cómo funcionan nuestras redes con los datos de test: para ello hemos creado dos vectores para almacenar los datos de pérdida y acierto de cada uno de los 8 casos.`evaluate()` los mostrará por pantalla."
      ],
      "metadata": {
        "id": "STdh3hG8vSnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = [0,0,0,0,0,0,0,0]\n",
        "test_acc = [0,0,0,0,0,0,0,0]\n",
        "for i in range(8):\n",
        "  print(\"CASO \", i+1)\n",
        "  test_loss[i], test_acc[i] = red[i].evaluate(test_images, test_labelsOH)\n",
        "#test_images no puede estar vectorizada, para que funcione tien que estar en 28, 28\n"
      ],
      "metadata": {
        "id": "iQszx7ISvWTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b801109-9b19-4d03-9374-9e6b5aea68ce"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CASO  1\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6175 - accuracy: 0.7935\n",
            "CASO  2\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4730 - accuracy: 0.8402\n",
            "CASO  3\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.2833 - accuracy: 0.6642\n",
            "CASO  4\n",
            "313/313 [==============================] - 2s 3ms/step - loss: 0.5146 - accuracy: 0.8240\n",
            "CASO  5\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.5291 - accuracy: 0.8240\n",
            "CASO  6\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4066 - accuracy: 0.8505\n",
            "CASO  7\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.7573 - accuracy: 0.7456\n",
            "CASO  8\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3965 - accuracy: 0.8585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viendo la teoría a priori sabemos que lo que debería ocurrir es que el caso con sigmoidea, rmsprop y 512 neuronas fuese aquel que mejor resultados diese ya que tiene el mayor número de neuronas, la función que mejor se aplica a las clasificaciones y la función de pérdida mejorada. Sin embargo, visto en los resultados para este caso particular sale que el mejor modelo de entrenamiento ha sido el que tiene todos los parámetros iguales salvo la función de activación que se cambia por RELU, esto puede deberse a su complejidad computacional o que para cada este caso en específico cambie y varíe.  "
      ],
      "metadata": {
        "id": "y_8-Cg_5u_Jo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Apartado 5"
      ],
      "metadata": {
        "id": "YLEu3zv9eqWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Queremos mostrar una imagen, en este caso la sexta, y su etiqueta correspondiente del conjunto de datos. Utilizamos la biblioteca Matplotlib para mostrar la imagen correspondiente a la sexta posición en el conjunto de datos."
      ],
      "metadata": {
        "id": "GY-u-wuD0JDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels[5])\n",
        "plt.imshow(test_images[5], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0yRQ6e_LjZfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos predict() para que se haga una predicción de cada uno de los 8 tipos de redes que tenemos sobre la sexta imagen de test. El resultado será un vector de 10 elementos en el que cada elemento representa la posibilidad de que dicho elemento sea el que está en la foto."
      ],
      "metadata": {
        "id": "o1u7E7lgHxOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(8):\n",
        "  print(\"CASO: \", j+1)\n",
        "  predictions = red[j].predict(test_images)\n",
        "  print(np.around(predictions[5], decimals = 3))"
      ],
      "metadata": {
        "id": "iWLrdR4qlHlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Efectivamente, el modelo que mejor se ha entrenado ha sido el modelo 6 pese a que teóricamente es en la red número 8. Sin embargo, el modelo 8 para esta imagen es muy preciso y da un resultado muy fiable, no como por ejemplo el caso 3.  "
      ],
      "metadata": {
        "id": "bi2_3O1B11ef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Apartado 6"
      ],
      "metadata": {
        "id": "DMIpxruEe_Z_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con las funciones `plot_image()` y `plot_value_array()` proporcionadas en el enunciado y ayudándonos de  dos bucles vamos a graficar la imagen de test y la gráfica de predicción para las 10 primeras imágenes y para cada uno de los 8 tipos de redes. Se podrá apreciar muy bien qué modelo acierta más, qué modelo falla más, etc."
      ],
      "metadata": {
        "id": "-lVCC8zrM6N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label.all() == true_label.all():\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label,\n",
        "                                100*np.max(predictions_array),\n",
        "                                true_label),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#00FF00\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('black')"
      ],
      "metadata": {
        "id": "g65jLFCq1DE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(8):\n",
        "  print(\"CASO: \", i+1)\n",
        "  predictions = red[i].predict(test_images)\n",
        "  for j in range(10):\n",
        "    plt.figure(figsize=(6,3))\n",
        "    plt.subplot(1,2,1)\n",
        "    plot_image(j, predictions[j], test_labels, test_images.reshape(10000,28,28))\n",
        "    plt.subplot(1,2,2)\n",
        "    plot_value_array(j, predictions[j],  test_labels)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "XyPv6HiZbe16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apartado 7\n"
      ],
      "metadata": {
        "id": "O4wvDHxbmVCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El nombre \"adam\" es una abreviatura de \"Adaptive Moment Estimation\". Adam combina técnicas de dos otros optimizadores populares: el Descenso de Gradiente Estocástico (SGD) y el Momento (Momentum).\n",
        "\n",
        "La idea principal detrás de **'adam'** es adaptar la tasa de aprendizaje durante el entrenamiento de la red de manera que sea más alta para parámetros que se actualizan con menos frecuencia y más baja para parámetros que se actualizan con más frecuencia. Cuando se agranda la tasa de aprendizaje, existe la probabilidad de saltarte algún mínimo, es por esto que a medida que se acerca al mínimo la tasa de aprendizaje va disminuyendo. De esta forma, converge más rápido y no corremos el riesgo de saltarnos ningún mínimo.\n",
        "\n",
        "La función de pérdida **'sparse_categorical_crossentropy'** (entropía cruzada categórica dispersa) se utiliza cuando no existe el one-hot encoding donde las clases están representadas con números enteros. Esto se utiliza sobre todo cuando un mismo objeto puede pertenecer a varias clases.   "
      ],
      "metadata": {
        "id": "oF6d_5VImMl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = GenerateTrain (10, 'sigmoid', 'adam', 5, 'sparse_categorical_crossentropy', labels_no_cat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbDQzd6hmbIP",
        "outputId": "e530caba-2003-474d-9509-7c4a9f582ddc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_8 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 10)                7850      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7960 (31.09 KB)\n",
            "Trainable params: 7960 (31.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 1.4255 - accuracy: 0.6491\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.8791 - accuracy: 0.7751\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.6892 - accuracy: 0.8033\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.5949 - accuracy: 0.8184\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5398 - accuracy: 0.8280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez entrenada esta red, vamos a ver si la variación realizada varía en algo nuestro reultados. Es decir, si sobrentrena, si mejora."
      ],
      "metadata": {
        "id": "2bEtNJwY5Ije"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_network, test_acc_network = network.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "DsQy0R__4rNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cabe destacar que hemos obtenido el mejor resultado dentro de todos aquellos que tenían 10 neuronas en la entrada. No son significativos los cambios pero es visto que mejora ligeramente."
      ],
      "metadata": {
        "id": "3pc7L57U5ZcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Apartado 3:"
      ],
      "metadata": {
        "id": "GlcC6d_EW3RP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a ver qué sucede cuando multiplicamos por 5 las épocas de entrenamiento de las redes del caso 2 y 7."
      ],
      "metadata": {
        "id": "UVimDPKfOHQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  print(\"CASO 2 con 25 épocas\")\n",
        "  red2a3 = GenerateTrain (matriz[1][0], matriz[1][1], matriz[1][2], 5*5, 'categorical_crossentropy', train_labels )\n",
        "  print(\"CASO 7 con 25 épocas\")\n",
        "  red7a3 = GenerateTrain (matriz[6][0], matriz[6][1], matriz[6][2], 5*5, 'categorical_crossentropy', train_labels )"
      ],
      "metadata": {
        "id": "i1ahBnZMox5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez entrenado se observa que el tiempo ha aumentado significativamente, sin embargo este tiempo de más puede ser muy beneficioso o bastante improductivo ya que pueden mejorar bastante los resultados o incluso empeorarlos ya que un número exagerado de épocas puede conducir al sobrentrenamiento, es por esto que vamos a testearlo para ver si el tiempo invertido computacionalmente en añadir estas épocas está bien."
      ],
      "metadata": {
        "id": "RYQ5ktS77hom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CASO 2 con 25 épocas\")\n",
        "test_loss_red2a3, test_acc_red2a3 = red2a3.evaluate(test_images, test_labelsOH)\n",
        "print(\"CASO 7 con 25 épocas\")\n",
        "test_loss_red7a3, test_acc_red7a3 = red7a3.evaluate(test_images, test_labelsOH)"
      ],
      "metadata": {
        "id": "Pk8-R9rK6U7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez testeado el código, podemos confirmar que no ha habido sobrentrenamiento ya que los resultados siguen siendo positivos. Además hay una ligera mejora ya que la precisión ha aumentado y la pérdida ha dismunuido. Cabe destacar que la que más ha mejorado ha sido la que más neuronas tenía. Sin embargo, consideramos que este tiempo invertido no es eficiente ya que la mejora no es tan significativa como el coste computacional de tardar solo un minuto menos en entrenar 2 redes que 8 redes con esa ampliación del número de épocas."
      ],
      "metadata": {
        "id": "MW7cXLKj9HpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusiones:\n",
        "Estábamos poco familiarizados con el entorno de trabajo de Jupyter Notebook, por lo que nos ha costado adaptarnos al principio. Además de que hacía tiempo que no programábamos en Python y que Keras era totalmente desconocido para nosotros. Aun así, nos ha gustado descubrir Keras y lo que puede hacer, porque aunque tuviéramos un poco oxidada nuestra programación en Python, guardábamos un buen recuerdo del año pasado porque nos pareció un lenguaje más moderno y ágil que C, pero sentimos que los problemas que estábamos resolviendo con Python eran muy básicos. Gracias a esta práctica, hemos podido comprobar que tanto Python como Keras conservan su fama de ser mas user-friendly que otros lenguajes como C, pero además hemos visto que son tanto o más potentes.\n",
        "\n",
        "Tuvimos algún problema al pasar el vector de etiquetas de las imágenes de entrenamiento a formato one-hot, porque en un principio lo hicimos dentro de la función <GenerateTrain>, y al llamarla varias veces, lo que nos estaba ocurriendo era que estabamos creando una matriz de varias dimensiones. Obviamente no compilaba.\n",
        "\n",
        "También tuvimos algún problema a la hora de evaluar las redes con las imágenes de test, porque intentamos vectorizar las imágenes como habíamos hecho con las imágenes de entreno, pero el error que nos salía era altísimo. Cuando no vectorizamos las imágenes de test, el acierto y el fallo son parecidos a las del entrenamiento con las imágenes de entrenamiento.\n",
        "\n",
        "A modo de conclusión, pese a que en un principio estábamos un poco sobrecogidos con la práctica, hemos podido organizarnos bien. En todo momento nos hemos ido informando sobre lo que iba avanzando cada uno y hemos tratado de comentar mucho a medida que íbamos avanzando en el código para recordar con más facilidad nuestras sensaciones, tanto cuando algo funcionaba como cuando no. Como aprendizaje para futuras prácticas, nos hemos dado cuenta de que en ocasiones, es mejor entender o investigar cosas por separado, interiorizarlas y probar con ellas, y después ya ponerlas en común. Por ejemplo, cuando desconocíamos el funcionamiento de <flatten()>, quedamos para investigar todos juntos, pero se avanzó poco. Fue más tarde y por separado cuando logramos entender el concepto."
      ],
      "metadata": {
        "id": "J--JqZXCXAd4"
      }
    }
  ]
}